{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook implements functions that do an API-call to the Obelisk database in order to get data for a specific 'thing' for a chosen metric and for a certain time period. These files are then stored locally and are merged together in bigger files for every different metric.\n",
    "\n",
    "## Inputs\n",
    " * basePath - Where to store the local files\n",
    " * Token - to access the Obelisk database\n",
    " * scopeID: name of the scope\n",
    " * list of things\n",
    " * list of metrics\n",
    " * time range for the query (advised to be one month)\n",
    " \n",
    "## Output\n",
    " * .csv files containing the data for a chosen metric, a chosen thing and the chosen time range\n",
    " * These files are merged in a bigger .csv file for a chosen metric and a chosen thing for the whole time range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta  \n",
    "import time\n",
    "import sys\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "import glob\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_csv(scopeID, listOfThings, listOfMetrics, startDate, endDate, myToken, basePath):\n",
    "    \"\"\"\n",
    "    This function will generate a local .csv-file per chosen Thing and Metric for a certain period.\n",
    "\n",
    "    Args:\n",
    "        scopeID: The ID of the scope as defined on the IoT-stack explorer\n",
    "        listOfthings: List of the things you want to query as defined on the IoT-stack explorer\n",
    "        listOfMetrics: List of metrics you want to query as defined on the IoT-stack explorer\n",
    "        startDate: Earliest date in datetime format\n",
    "        endDate: Latest date in datetime format\n",
    "        myToken: Token generated through Swagger UI\n",
    "\n",
    "    Returns:\n",
    "        Nothing. Saves the .csv-file locally or prints an error message\n",
    "\n",
    "    ValueError:\n",
    "        ValueError: Raises an exception.\n",
    "    \"\"\"\n",
    "    #Convert timestamp to milliseconds\n",
    "    startTime = int(startDate.timestamp())*1000\n",
    "    endTime = int(endDate.timestamp())*1000\n",
    "    \n",
    "    for thingID in listOfThings:\n",
    "        for metricID in listOfMetrics:\n",
    "            # Specify the right API call\n",
    "            myUrlQuery = 'https://idlab-iot.tengu.io/api/v1/scopes/{scope}/query/{metric}/events?from={start}&to={end}&things={thing}&orderByTime=asc'\\\n",
    "                .format(scope = scopeID, metric = metricID, start=startTime, end=endTime, thing=thingID)\n",
    "\n",
    "            headers = {\n",
    "                'accept': 'application/json',\n",
    "                'authorization': 'Bearer {0}'.format(myToken),\n",
    "            }\n",
    "            # Execure query\n",
    "            response = requests.get(myUrlQuery, headers=headers)\n",
    "            try:\n",
    "                # Transform to json format\n",
    "                data = response.json()\n",
    "                if len(data)!=0:\n",
    "                    # Get columns names and values\n",
    "                    column_names = data['columns']; #print(column_names)\n",
    "                    values = data['values']\n",
    "                    # Get data in pandas DataFrame format\n",
    "                    df = pd.DataFrame.from_dict(values)\n",
    "                    df.columns = column_names\n",
    "                    result = df[['time','value']]\n",
    "                    # Set path\n",
    "                    if thingID == 'davis.davis.weather.1':\n",
    "                        path=basePath +'\\\\weather_data'\n",
    "                        if not os.path.exists(path):\n",
    "                            os.mkdir(path)\n",
    "                            print(\"Directory \" , path ,  \" Created \")\n",
    "                    else:\n",
    "                        path=basePath+ '\\\\battery_data'\n",
    "                        if not os.path.exists(path):\n",
    "                            os.mkdir(path)\n",
    "                            print(\"Directory \" , path ,  \" Created \")\n",
    "                        path=path + '\\\\' + str(thingID)\n",
    "                        if not os.path.exists(path):\n",
    "                            os.mkdir(path)\n",
    "                            print(\"Directory \" , path ,  \" Created \")\n",
    "                    # Save DataFrame to a local file\n",
    "                    result.to_csv(path+'\\\\'+str(metricID)+'_'+startDate.strftime('%Y-%m')+'.csv')\n",
    "\n",
    "            except ValueError:  \n",
    "                print(\"Decoding JSON has failed. Probably the token has expired\")\n",
    "                print(ValueError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metric_data(listOfThings, listOfMetrics, basePath):\n",
    "    \"\"\"\n",
    "    This function will merge the local .csv-files of a certain metric into one bigger .csv-file for that metric.\n",
    "\n",
    "    Args:\n",
    "        listOfthings: List of the things you want to query as defined on the IoT-stack explorer\n",
    "        listOfMetrics: List of metrics you want to query as defined on the IoT-stack explorer\n",
    "        basePath: path to the base folder of your project\n",
    "\n",
    "    Returns:\n",
    "        Nothing. Saves the .csv-file locally\n",
    "    \"\"\"\n",
    "    tableList = listOfMetrics.copy()\n",
    "    for thingID in listOfThings:\n",
    "        # Set path\n",
    "        if thingID == 'davis.davis.weather.1':\n",
    "            path=basePath +'\\\\weather_data'\n",
    "        else:\n",
    "            path=basePath + '\\\\battery_data' + '\\\\' + str(thingID)\n",
    "        \n",
    "        # Remove older merged files\n",
    "        for filename in glob.glob(path + '\\\\' + \"*_merged.csv\"):\n",
    "                os.remove(filename) \n",
    "            \n",
    "        ##### This loop merges all the csv-files in new dataframes\n",
    "        for i in range(0,len(listOfMetrics)):\n",
    "            metricID = listOfMetrics[i]\n",
    "            \n",
    "            dataList = glob.glob(path+'\\\\'+metricID+'*')\n",
    "            for j in range(0,len(dataList)):\n",
    "                if j == 0:\n",
    "                    tableList[i] = pd.read_csv(dataList[j],  index_col=[0])\n",
    "                else :\n",
    "                    tableList[i] = tableList[i].append(pd.read_csv(dataList[j], index_col=[0]),ignore_index=True)\n",
    "            tableList[i].to_csv(path+'\\\\'+metricID+'_merged.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basePath = r'D:\\Documents\\Thesis\\Case 1 - data'\n",
    "basePath = r'C:\\Users\\JeffG\\Desktop\\Case 1 - data'\n",
    "myToken = 'eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICIwUnhaVzd0N1d5aEczaEo3cUhoM3hQa3MzbkthTUE5Zy04SnozY2trQ3EwIn0.eyJqdGkiOiI5OThmOGZmZi01NjllLTQ4ZmQtYjE5NS1lNTI5OTZhNjg2NDUiLCJleHAiOjE1NTQ3MDk1MTgsIm5iZiI6MCwiaWF0IjoxNTU0NzA4OTE4LCJpc3MiOiJodHRwczovL2lkbGFiLWlvdC50ZW5ndS5pby9hdXRoL3JlYWxtcy9pZGxhYi1pb3QiLCJhdWQiOiJwb2xpY3ktZW5mb3JjZXIiLCJzdWIiOiI3NGVjNTQzYi03Yjc1LTQ1ZGItOWExNy0xMDY5OTlmYmU3OWEiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJzd2FnZ2VyLXVpIiwibm9uY2UiOiI0MjQ0MmE3MS1jNDBmLTQ1MWQtYTcwZi1jNTExNWVmOGQwMWEiLCJhdXRoX3RpbWUiOjE1NTQ3MDc1NjYsInNlc3Npb25fc3RhdGUiOiIwYWI1MjdjOS1kZGVjLTQ3MWUtYjM1OS01OGQ5ODNkMTdhMjIiLCJhY3IiOiIwIiwiYWxsb3dlZC1vcmlnaW5zIjpbImh0dHBzOi8vaWRsYWItaW90LnRlbmd1LmlvIiwiaHR0cDovL2xvY2FsaG9zdDo1NTU1Il0sInJlc291cmNlX2FjY2VzcyI6eyJwb2xpY3ktZW5mb3JjZXIiOnsicm9sZXMiOlsidXNlcjp2aWV3Il19fSwiYXV0aG9yaXphdGlvbiI6eyJwZXJtaXNzaW9ucyI6W3sicnNpZCI6IjQxOGFiMGYzLWE5NTQtNGEwMS04ZTdlLWFlZGQzN2VjZTcyMyIsInJzbmFtZSI6ImRhdGE6c2NvcGVkOnZpZXcifV19LCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGVtYWlsIGNvdC1zY29wZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicmlnaHRzIjpbXSwibmFtZSI6IkplZmYgR2V1ZGVucyIsImdyb3VwcyI6WyIvYWxsLXVzZXJzIiwiL2NvdC90aGVzaXMiXSwicHJlZmVycmVkX3VzZXJuYW1lIjoiZ2V1ZGVucy5qZWZmQGdtYWlsLmNvbSIsImdpdmVuX25hbWUiOiJKZWZmIiwiZmFtaWx5X25hbWUiOiJHZXVkZW5zIiwiZW1haWwiOiJnZXVkZW5zLmplZmZAZ21haWwuY29tIiwicGljdHVyZSI6Imh0dHBzOi8vbGg1Lmdvb2dsZXVzZXJjb250ZW50LmNvbS8tRTYxVzBvTmFlOUkvQUFBQUFBQUFBQUkvQUFBQUFBQUFCd2MvUExDNy1mNTdnek0vcGhvdG8uanBnP3N6PTUwIn0.PYi-DU84F-KWYTDKV8oxi46Bgc_sVqPDiecLrUrB-I6-xgrDZuVxr5raNH1wH8DCnlB-SPFZEsXt3gOzj8jLv29ndNkx3edqfSQvHSdRiFgM1OmCL2JfgNre2QVBTtL0_nPN3uZyYNCqb8KexwLYIQKUc1tK4_YFl2BhCajTsASFk-_xBKcy5w9DYeRvEbayeew-BdK_1qSv5ilz8XMPYKyGOZh4e58bOpGdFDGxXOTkkQKAvPZnoRBX1pL7zUHDfEvcUmfMMnVsrBehXbURUhSjZYX89VVI-ZWIXSw0O7sQ821LHwvMbSjh1ZUab3Lo4AHfA4aJJ9TeQ0PihvFJwQ'\n",
    "scopeID = 'cot.smart_lighting'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfThings = ['davis.davis.weather.1']\n",
    "listOfMetrics = ['environment.light','environment.temperature','weather.uv','environment.relativehumidity','weather.pressure', 'weather.rainrate', 'weather.windspeed']\n",
    "# listOfMetrics = ['weather.windspeed']\n",
    "startDate = datetime(2019, 3, 1, 1, 0)\n",
    "endDate = datetime(2019, 4, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_csv(scopeID, listOfThings, listOfMetrics, startDate, endDate, myToken, basePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JeffG\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merge_metric_data(listOfThings, listOfMetrics, basePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Battery data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfThings = ['munisense.msup1g30034', 'munisense.msup1i70124', 'munisense.msup1h90115', 'munisense.msup1h90103']\n",
    "listOfMetrics = ['Power.BatteryState','Power.BatteryVoltHR','Power.PercentageRemaining','Power.TimeRemaining']\n",
    "startDate = datetime(2018, 8, 1, 1, 0)\n",
    "endDate = datetime(2018, 9, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_csv(scopeID, listOfThings, listOfMetrics, startDate, endDate, myToken, basePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_metric_data(listOfThings, listOfMetrics, basePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
